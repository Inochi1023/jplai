import streamlit as st
import speech_recognition as sr
import google.generativeai as genai
from gtts import gTTS
import io
import base64
import tempfile
import os
from audio_recorder_streamlit import audio_recorder

gemini_api_key = "AIzaSyAoy_kLi5udJ7rl58s8URzp7q-1W8lLve4"


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì¼ë³¸ì–´ ë°œìŒ êµì • AI ì–´ì‹œìŠ¤í„´íŠ¸",
    page_icon="ğŸ—¾",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
.main-header {
    text-align: center;
    color: #2E86AB;
    margin-bottom: 2rem;
}
.chat-message {
    padding: 1rem;
    border-radius: 10px;
    margin: 1rem 0;
}
.user-message {
    background-color: #E3F2FD;
    border-left: 4px solid #2196F3;
}
.ai-message {
    background-color: #F3E5F5;
    border-left: 4px solid #9C27B0;
}
.translation-box {
    background-color: #E8F5E8;
    border: 1px solid #4CAF50;
    border-radius: 5px;
    padding: 10px;
    margin-top: 10px;
    font-style: italic;
    color: #2E7D32;
}
</style>
""", unsafe_allow_html=True)

# ì œëª©
st.markdown("<h1 class='main-header'>ğŸ—¾ ì¼ë³¸ì–´ ë°œìŒ êµì • AI ì–´ì‹œìŠ¤í„´íŠ¸</h1>", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # ì–¸ì–´ ì„¤ì •
    recognition_lang = st.selectbox("ìŒì„± ì¸ì‹ ì–¸ì–´", ["ja-JP", "ko-KR"], index=0)

    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# Gemini ì„¤ì •
if gemini_api_key:
    genai.configure(api_key=gemini_api_key)
    model = genai.GenerativeModel('gemini-2.0-flash')


def recognize_speech_from_audio(audio_bytes):
    """ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ì—ì„œ ìŒì„±ì„ ì¸ì‹í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ìŒì„± ì¸ì‹ê¸° ì´ˆê¸°í™”
        r = sr.Recognizer()

        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_file_path = tmp_file.name

        # ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ ìŒì„± ì¸ì‹
        with sr.AudioFile(tmp_file_path) as source:
            audio = r.record(source)
            text = r.recognize_google(audio, language=recognition_lang)

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.unlink(tmp_file_path)

        return text
    except sr.UnknownValueError:
        return "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except sr.RequestError as e:
        return f"ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}"
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}"


def get_gemini_response(user_input):
    """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ë³¸ì–´ ë°œìŒ êµì • ë° í”¼ë“œë°± ìƒì„±"""
    try:
        prompt = f"""
        ë„ˆëŠ” ì¼ë³¸ì–´ë¡œ ì‚¬ìš©ìì™€ ì¼ìƒì ì¸ ëŒ€í™”ë¥¼ í•  ê±°ê³ 
        ì‚¬ìš©ìì˜ ë°œìŒì„ ë¶„ì„í•´ì„œ ì •í™•ë„ë¥¼ 0%~100%ë¡œ ë‚˜íƒ€ë‚´ì£¼ê³  ë°œìŒêµì •ì„ í• ìˆ˜ ìˆê²Œ ê·¸ ë°œìŒì— ëŒ€í•œ í”¼ë“œë°±ì„ í•´ì£¼ê³  êµì •í•  ìˆ˜ ìˆëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ì •í•´ì£¼ê³ 
        ë„ˆê°€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°€ë©´ ë¼
        ì‚¬ìš©ì ì…ë ¥: "{user_input}"
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        "ë‹¹ì‹ ì˜ ë°œìŒ ì •í™•ë„:N%\n
        ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„:(ë„ˆê°€ íŒë‹¨í–ˆì„ë•Œ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„)\n
        (ì´ì–´ë‚˜ê°ˆ ëŒ€í™”)"
        
        ì˜ˆ) ì‚¬ìš©ì ì…ë ¥ì´ "ã“ã‚“ã¡ã¯"ì´ë©´
        ë„ˆëŠ” "ì •í™•ë„:5/10\n
        ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„:ã“ã‚“ã«ã¡ã¯\n
        ã“ã‚“ã«ã¡ã¯! ä½•ã‚’è¨€ã£ã¦ã¿ã¾ã—ã‚‡ã†ã‹ï¼Ÿ"
        
        ì´ì œë¶€í„° ë°”ë¡œ ëŒ€í™” ì‹œì‘ì´ì•¼
        ì•Œê² ë‹¤ëŠ” ë§ í•˜ì§€ ë§ê³  ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ë„ë¡ í•´
        """

        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Gemini API ì˜¤ë¥˜: {e}"


def text_to_speech(text, lang='ja'):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    try:
        # AI ì‘ë‹µì—ì„œ ì¼ë³¸ì–´ ëŒ€í™” ë¶€ë¶„ë§Œ ì¶”ì¶œ
        lines = text.split('\n')
        japanese_dialogue = ""

        # ê° ë¼ì¸ì„ í™•ì¸í•˜ì—¬ ì¼ë³¸ì–´ ëŒ€í™” ë¶€ë¶„ ì°¾ê¸°
        for line in lines:
            line = line.strip()
            # "ë‹¹ì‹ ì˜ ë°œìŒ ì •í™•ë„"ë‚˜ "ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„" ë¼ì¸ì€ ê±´ë„ˆë›°ê¸°
            if line.startswith("ë‹¹ì‹ ì˜ ë°œìŒ ì •í™•ë„") or line.startswith("ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„"):
                continue
            # ì¼ë³¸ì–´ê°€ í¬í•¨ëœ ë¼ì¸ì´ë©´ì„œ ëŒ€í™” ë¶€ë¶„ì¸ ê²½ìš°
            if any('\u3040' <= char <= '\u309F' or  # íˆë¼ê°€ë‚˜
                   '\u30A0' <= char <= '\u30FF' or  # ì¹´íƒ€ì¹´ë‚˜
                   '\u4E00' <= char <= '\u9FAF'  # í•œì
                   for char in line):
                japanese_dialogue = line
                break

        # ì¼ë³¸ì–´ ëŒ€í™”ê°€ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¼ë³¸ì–´ ì¶”ì¶œ
        if not japanese_dialogue:
            import re
            japanese_parts = re.findall(r'[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠä¸€-é¾¯ï¼ï¼Ÿã€‚ã€]+', text)
            if japanese_parts:
                japanese_dialogue = ''.join(japanese_parts)
            else:
                japanese_dialogue = "ã“ã‚“ã«ã¡ã¯"  # ê¸°ë³¸ê°’

        print(f"TTSë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸: {japanese_dialogue}")  # ë””ë²„ê¹…ìš©

        tts = gTTS(text=japanese_dialogue, lang=lang, slow=False)

        # ë©”ëª¨ë¦¬ì— ì˜¤ë””ì˜¤ ì €ì¥
        audio_buffer = io.BytesIO()
        tts.write_to_fp(audio_buffer)
        audio_buffer.seek(0)

        return audio_buffer.getvalue()
    except Exception as e:
        st.error(f"ìŒì„± í•©ì„± ì˜¤ë¥˜: {e}")
        return None


def play_audio(audio_bytes):
    """ì˜¤ë””ì˜¤ ì¬ìƒì„ ìœ„í•œ HTML ìƒì„±"""
    if audio_bytes:
        audio_base64 = base64.b64encode(audio_bytes).decode()
        audio_html = f"""
        <audio controls autoplay>
            <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
            Your browser does not support the audio element.
        </audio>
        """
        return audio_html
    return ""


# ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸ¤ ìŒì„± ì…ë ¥")

    # ì˜¤ë””ì˜¤ ë…¹ìŒê¸°
    audio_bytes = audio_recorder(
        text="ë…¹ìŒ ì‹œì‘/ì¤‘ì§€",
        recording_color="#e74c3c",
        neutral_color="#34495e",
        icon_name="microphone",
        icon_size="2x"
    )

    if audio_bytes and gemini_api_key:
        with st.spinner("ìŒì„±ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # ìŒì„± ì¸ì‹
            recognized_text = recognize_speech_from_audio(audio_bytes)

            if recognized_text and "ì˜¤ë¥˜" not in recognized_text and "ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in recognized_text:
                # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                st.session_state.messages.append({"role": "user", "content": recognized_text})

                # Geminië¡œ ë¶„ì„
                ai_response = get_gemini_response(recognized_text)
                
                # ë²ˆì—­ ì¶”ê°€
                translation = translate_japanese_to_korean(ai_response)
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": ai_response,
                    "translation": translation
                })

                # TTS ìƒì„±
                audio_response = text_to_speech(ai_response)
                if audio_response:
                    st.session_state.messages[-1]["audio"] = audio_response
            else:
                st.error(recognized_text)

    elif audio_bytes and not gemini_api_key:
        st.warning("Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

with col2:
    st.subheader("ğŸ“Š í•™ìŠµ í†µê³„")

    # ê°„ë‹¨í•œ í†µê³„
    total_messages = len([msg for msg in st.session_state.messages if msg["role"] == "user"])
    st.metric("ì´ ì—°ìŠµ íšŸìˆ˜", total_messages)

    if total_messages > 0:
        st.success("ê³„ì† ì—°ìŠµí•˜ì„¸ìš”! ğŸ’ª")

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
st.subheader("ğŸ’¬ ëŒ€í™” ê¸°ë¡")

for message in st.session_state.messages:
    if message["role"] == "user":
        st.markdown(f"""
        <div class="chat-message user-message">
            <strong>ğŸ—£ï¸ ì‚¬ìš©ì:</strong><br>
            {message["content"]}
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chat-message ai-message">
            <strong>ğŸ¤– AI ì„ ìƒë‹˜:</strong><br>
            {message["content"]}
        </div>
        """, unsafe_allow_html=True)


        # ì˜¤ë””ì˜¤ê°€ ìˆìœ¼ë©´ ì¬ìƒ
        if "audio" in message:
            audio_html = play_audio(message["audio"])
            if audio_html:
                st.markdown(audio_html, unsafe_allow_html=True)

# ì‚¬ìš©ë²• ì•ˆë‚´
if not st.session_state.messages:
    st.info("""
    ğŸ“ **ì‚¬ìš©ë²•:**
    1. ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¼ë³¸ì–´ë¡œ ë§í•´ë³´ì„¸ìš”!
    2. AIê°€ ì •í™•ë„ë‘ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤!
    3. AIë‘ ì¬ë¯¸ìˆê²Œ ëŒ€í™”í•˜ë©° ê³µë¶€í•´ë´ìš”!
    """)
